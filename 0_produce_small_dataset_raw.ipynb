{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from PIL import Image\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from colour_demosaicing import (\n",
    "    ROOT_RESOURCES_EXAMPLES,\n",
    "    demosaicing_CFA_Bayer_bilinear,\n",
    "    demosaicing_CFA_Bayer_Malvar2004,\n",
    "    demosaicing_CFA_Bayer_Menon2007,\n",
    "    mosaicing_CFA_Bayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6231f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RawHandler.RawHandler import RawHandler\n",
    "from RawHandler.utils import linear_to_srgb\n",
    "from src.training.load_config import load_config\n",
    "\n",
    "def apply_gamma(x, gamma=2.2):\n",
    "    return x ** (1 / gamma)\n",
    "\n",
    "def reverse_gamma(x, gamma=2.2):\n",
    "    return x ** gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e21592",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = load_config()\n",
    "raw_path = Path(run_config['base_data_dir'])\n",
    "outpath = Path(run_config['cropped_raw_subdir'])\n",
    "alignment_csv =  outpath / run_config['align_csv']\n",
    "colorspace = run_config['colorspace']\n",
    "crop_size = run_config['cropped_raw_size']\n",
    "file_list = os.listdir(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783efea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_images_by_scene(file_list, min_iso=100):\n",
    "    \"\"\"\n",
    "    Given a list of RAW image file paths:\n",
    "      1. Extract ISO from filenames\n",
    "      2. Remove files with ISO < min_iso\n",
    "      3. Group by scene name\n",
    "      4. Pair each image with the lowest-ISO version of the scene\n",
    "\n",
    "    Args:\n",
    "        file_list (list of str): Paths to RAW files\n",
    "        min_iso (int): Minimum ISO to keep (default=100)\n",
    "\n",
    "    Returns:\n",
    "        dict: {scene_name: [(img_path, gt_path), ...]}\n",
    "    \"\"\"\n",
    "    iso_pattern = re.compile(r\"_ISO(\\d+)_\")\n",
    "    scene_pairs = {}\n",
    "\n",
    "    # Step 1: Extract iso and scene\n",
    "    images = []\n",
    "    for path in file_list:\n",
    "        filename = os.path.basename(path)\n",
    "        match = iso_pattern.search(filename)\n",
    "        if not match:\n",
    "            continue  # skip if no ISO\n",
    "        iso = int(match.group(1))\n",
    "        if iso < min_iso:\n",
    "            continue  # filter out low ISOs\n",
    "\n",
    "        # Extract scene name:\n",
    "        if \"_GT_\" in filename:\n",
    "            scene = filename.split(\"_GT_\")[0]\n",
    "        else:\n",
    "            # Scene = part before \"_ISO\"\n",
    "            scene = filename.split(\"_ISO\")[0]\n",
    "        if 'X-Trans' in filename:\n",
    "            continue\n",
    "\n",
    "        images.append((scene, iso, path))\n",
    "\n",
    "    # Step 2: Group by scene\n",
    "    grouped = defaultdict(list)\n",
    "    for scene, iso, path in images:\n",
    "        grouped[scene].append((iso, path))\n",
    "\n",
    "    # Step 3: For each scene, pick lowest ISO as GT\n",
    "    for scene, iso_paths in grouped.items():\n",
    "        iso_paths.sort(key=lambda x: x[0])  # sort by ISO ascending\n",
    "        gt_iso, gt_path = iso_paths[0]      # lowest ISO ≥ min_iso\n",
    "        pairs = [(path, gt_path) for iso, path in iso_paths if path != gt_path]\n",
    "        scene_pairs[scene] = pairs\n",
    "\n",
    "    return scene_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af686c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_file_list = pair_images_by_scene(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ab100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(impath, crop_size=crop_size):\n",
    "        rh = RawHandler(impath)\n",
    "        \n",
    "        width, height = rh.raw.shape\n",
    "\n",
    "        # Check if the image is large enough to be cropped.\n",
    "        if width < crop_size or height < crop_size:\n",
    "            im = rh.apply_colorspace_transform(colorspace=colorspace)\n",
    "        else:\n",
    "            # Calculate the coordinates for the center crop.\n",
    "            left = (width - crop_size) // 2\n",
    "            top = (height - crop_size) // 2\n",
    "\n",
    "            # Ensure the top-left corner is on an even pixel coordinate for Bayer alignment.\n",
    "            if left % 2 != 0:\n",
    "                left -= 1\n",
    "            if top % 2 != 0:\n",
    "                top -= 1\n",
    "            \n",
    "            # Calculate the bottom-right corner based on the adjusted top-left corner.\n",
    "            # Since crop_size is even, right and bottom will also be even.\n",
    "            right = left + crop_size\n",
    "            bottom = top + crop_size\n",
    "        return rh.raw[left:right, top:bottom], rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b63be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pidng.core import RAW2DNG, DNGTags, Tag\n",
    "from pidng.defs import *\n",
    "\n",
    "def get_ratios(string, rh):\n",
    "    return [x.as_integer_ratio() for x in rh.full_metadata[string].values]\n",
    "\n",
    "\n",
    "def rational_wb(rh, denominator=1000):\n",
    "    wb = np.array(rh.core_metadata.camera_white_balance)\n",
    "    numerator_matrix = np.round(wb * denominator).astype(int)\n",
    "    return [[num, denominator] for num in numerator_matrix]\n",
    "def convert_ccm_to_rational(matrix_3x3, denominator=10000):\n",
    "\n",
    "    numerator_matrix = np.round(matrix_3x3 * denominator).astype(int)\n",
    "    numerators_flat = numerator_matrix.flatten()\n",
    "    ccm_rational = [[num, denominator] for num in numerators_flat]\n",
    "    \n",
    "    return ccm_rational\n",
    "\n",
    "\n",
    "def get_as_shot_neutral(rh, denominator=10000):\n",
    "\n",
    "    cam_mul = rh.core_metadata.camera_white_balance\n",
    "    \n",
    "    if cam_mul[0] == 0 or cam_mul[2] == 0:\n",
    "        return [[denominator, denominator], [denominator, denominator], [denominator, denominator]]\n",
    "\n",
    "    r_neutral = cam_mul[1] / cam_mul[0]\n",
    "    g_neutral = 1.0 \n",
    "    b_neutral = cam_mul[1] / cam_mul[2]\n",
    "\n",
    "    return [\n",
    "        [int(r_neutral * denominator), denominator],\n",
    "        [int(g_neutral * denominator), denominator],\n",
    "        [int(b_neutral * denominator), denominator],\n",
    "    ]\n",
    "\n",
    "\n",
    "def to_dng(uint_img, rh, filepath):\n",
    "    width = uint_img.shape[1]\n",
    "    height = uint_img.shape[0]\n",
    "    bpp = 16\n",
    "\n",
    "    ccm1 = convert_ccm_to_rational(rh.core_metadata.rgb_xyz_matrix[:3, :])\n",
    "    t = DNGTags()\n",
    "    t.set(Tag.ImageWidth, width)\n",
    "    t.set(Tag.ImageLength, height)\n",
    "    t.set(Tag.TileWidth, width)\n",
    "    t.set(Tag.TileLength, height)\n",
    "    t.set(Tag.BitsPerSample, bpp)\n",
    "\n",
    "    t.set(Tag.SamplesPerPixel, 1) \n",
    "    t.set(Tag.PlanarConfiguration, 1) \n",
    "\n",
    "    t.set(Tag.TileWidth, width)\n",
    "    t.set(Tag.TileLength, height)\n",
    "    t.set(Tag.PhotometricInterpretation, PhotometricInterpretation.Color_Filter_Array)\n",
    "    t.set(Tag.CFARepeatPatternDim, [2,2])\n",
    "    t.set(Tag.CFAPattern, CFAPattern.RGGB)\n",
    "    bl = rh.core_metadata.black_level_per_channel\n",
    "    t.set(Tag.BlackLevelRepeatDim, [2,2])\n",
    "    t.set(Tag.BlackLevel, bl)\n",
    "    t.set(Tag.WhiteLevel, rh.core_metadata.white_level)\n",
    "\n",
    "    t.set(Tag.BitsPerSample, bpp)\n",
    "\n",
    "    t.set(Tag.ColorMatrix1, ccm1)\n",
    "    t.set(Tag.CalibrationIlluminant1, CalibrationIlluminant.D65)\n",
    "    wb = get_as_shot_neutral(rh)\n",
    "    t.set(Tag.AsShotNeutral, wb)\n",
    "    t.set(Tag.BaselineExposure, [[0,100]])\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        t.set(Tag.Make, rh.full_metadata['Image Make'].values)\n",
    "        t.set(Tag.Model, rh.full_metadata['Image Model'].values)\n",
    "        exposures = get_ratios('EXIF ExposureTime', rh)\n",
    "        fnumber = get_ratios('EXIF FNumber', rh)\n",
    "        ExposureBiasValue = get_ratios('EXIF ExposureBiasValue', rh) \n",
    "        FocalLength = get_ratios('EXIF FocalLength', rh) \n",
    "        t.set(Tag.FocalLength, FocalLength)\n",
    "        t.set(Tag.EXIFPhotoLensModel, rh.full_metadata['EXIF LensModel'].values)\n",
    "        t.set(Tag.ExposureBiasValue, ExposureBiasValue)\n",
    "        t.set(Tag.ExposureTime, exposures)\n",
    "        t.set(Tag.FNumber, fnumber)\n",
    "        t.set(Tag.PhotographicSensitivity, rh.full_metadata['EXIF ISOSpeedRatings'].values)\n",
    "        t.set(Tag.Orientation, rh.full_metadata['Image Orientation'].values[0])\n",
    "    except:\n",
    "        \"ok\"\n",
    "    t.set(Tag.DNGVersion, DNGVersion.V1_4)\n",
    "    t.set(Tag.DNGBackwardVersion, DNGVersion.V1_2)\n",
    "    t.set(Tag.PreviewColorSpace, PreviewColorSpace.Adobe_RGB)\n",
    "\n",
    "    r = RAW2DNG()\n",
    "\n",
    "    r.options(t, path=\"\", compress=False)\n",
    "\n",
    "    r.convert(uint_img, filename=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07151d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tqdm(pair_file_list.keys()):\n",
    "    image_pairs = pair_file_list[key]\n",
    "    for noisy, gt in image_pairs:\n",
    "        noisy_path = outpath / (noisy)\n",
    "        if not os.path.exists(str(noisy_path)+'.dng'):\n",
    "            print(noisy_path)\n",
    "            if noisy.endswith(('.cr2', '.nef', '.arw', '.orf', '.raf', '.pef', '.crw', '.dng')):\n",
    "                bayer, rh = get_file(f'{raw_path}/{noisy}')\n",
    "                to_dng(bayer, rh, str(noisy_path))\n",
    "\n",
    "\n",
    "        gt_path = outpath / (gt)\n",
    "        if not os.path.exists(str(gt_path)+'.dng'):\n",
    "            print(gt_path)\n",
    "            bayer, rh = get_file(f'{raw_path}/{gt}')\n",
    "            to_dng(bayer, rh, str(gt_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing data is properly copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad377b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhdng = RawHandler(str(outpath / \"Bayer_MuseeL-sol-A7C-brighter_ISO100_sha1=18eaa9931d9a0f6f0511552ef6bf2fd040d82878.arw.dng\"))\n",
    "rh = RawHandler('/Volumes/EasyStore/RAWNIND/Bayer_MuseeL-sol-A7C-brighter_ISO100_sha1=18eaa9931d9a0f6f0511552ef6bf2fd040d82878.arw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fa141",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdng = rhdng.as_rgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45796c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = rh.raw.shape\n",
    "\n",
    "left = (width - crop_size) // 2\n",
    "top = (height - crop_size) // 2\n",
    "\n",
    "if left % 2 != 0:\n",
    "    left -= 1\n",
    "if top % 2 != 0:\n",
    "    top -= 1\n",
    "\n",
    "right = left + crop_size\n",
    "bottom = top + crop_size\n",
    "\n",
    "im = rh.as_rgb(dims=(left, right, top, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdng-im).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c495ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from  torch.utils.data import Dataset\n",
    "import imageio\n",
    "from colour_demosaicing import (\n",
    "    ROOT_RESOURCES_EXAMPLES,\n",
    "    demosaicing_CFA_Bayer_bilinear,\n",
    "    demosaicing_CFA_Bayer_Malvar2004,\n",
    "    demosaicing_CFA_Bayer_Menon2007,\n",
    "    mosaicing_CFA_Bayer)\n",
    "\n",
    "from src.training.utils import inverse_gamma_tone_curve, cfa_to_sparse\n",
    "import numpy as np\n",
    "import torch \n",
    "from src.training.align_images import apply_alignment, align_clean_to_noisy\n",
    "from pathlib import Path\n",
    "from RawHandler.RawHandler import RawHandler\n",
    "\n",
    "\n",
    "\n",
    "def global_affine_match(A, D, mask=None):\n",
    "    \"\"\"\n",
    "    Fit D ≈ a + b*A with least squares.\n",
    "    A, D : 2D arrays, same shape (linear values)\n",
    "    mask : optional boolean array, True=use pixel\n",
    "    returns: a, b, D_pred, D_resid (D - (a + b*A))\n",
    "    \"\"\"\n",
    "    A = A.ravel().astype(np.float64)\n",
    "    D = D.ravel().astype(np.float64)\n",
    "    if mask is None:\n",
    "        mask = np.isfinite(A) & np.isfinite(D)\n",
    "    else:\n",
    "        mask = mask.ravel() & np.isfinite(A) & np.isfinite(D)\n",
    "\n",
    "    A0 = A[mask]\n",
    "    D0 = D[mask]\n",
    "    # design matrix [1, A]\n",
    "    X = np.vstack([np.ones_like(A0), A0]).T\n",
    "    coef, *_ = np.linalg.lstsq(X, D0, rcond=None)\n",
    "    a, b = coef[0], coef[1]\n",
    "    D_pred = (a + b * A).reshape(-1)\n",
    "    D_pred = D_pred.reshape(A.shape) if False else (a + b * A).reshape((-1,))  # keep flatten\n",
    "\n",
    "    return a, b, (a + b * A)\n",
    "\n",
    "\n",
    "def random_crop_dim(shape, crop_size, buffer, validation=False):\n",
    "        h, w = shape\n",
    "        if not validation:\n",
    "            top = np.random.randint(0 + buffer, h - crop_size - buffer)\n",
    "            left = np.random.randint(0 + buffer, w - crop_size - buffer)\n",
    "        else:\n",
    "            top = (h - crop_size) // 2\n",
    "            left = (w - crop_size) // 2\n",
    "\n",
    "        if top % 2 != 0: top = top - 1\n",
    "        if left % 2 != 0: left = left - 1\n",
    "        bottom = top + crop_size\n",
    "        right = left + crop_size\n",
    "        return (left, right, top, bottom)\n",
    "\n",
    "class RawDatasetDNG(Dataset):\n",
    "    def __init__(self, path, csv, colorspace, crop_size=180, buffer=10, validation=False, run_align=False, dimensions=2000):\n",
    "        super().__init__()\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.path = path\n",
    "        self.crop_size = crop_size\n",
    "        self.buffer = buffer\n",
    "        self.coordinate_iso = 6400\n",
    "        self.validation=validation\n",
    "        self.run_align = run_align\n",
    "        self.dtype = np.float16\n",
    "        self.dimensions = dimensions\n",
    "        self.colorspace = colorspace\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Load images\n",
    "        name =  Path(f\"{row.bayer_path}\").name\n",
    "        name = str(self.path / name.replace('_bayer.jpg', '.dng'))\n",
    "        noisy_rh = RawHandler(name)\n",
    "        \n",
    "        name =  Path(f\"{row.gt_path}\").name\n",
    "        name = str(self.path / name.replace('.jpg', '.dng'))\n",
    "        gt_rh = RawHandler(name)\n",
    "\n",
    "\n",
    "        dims = random_crop_dim(noisy_rh.raw.shape, self.crop_size, self.buffer, validation=self.validation)\n",
    "        bayer_data = noisy_rh.apply_colorspace_transform(dims=dims, colorspace=self.colorspace)\n",
    "        noisy = noisy_rh.as_rgb(dims=dims, colorspace=self.colorspace)\n",
    "        rggb = noisy_rh.as_rggb(dims=dims, colorspace=self.colorspace)\n",
    "\n",
    "        expanded_dims = [dims[0]-self.buffer, dims[1]+self.buffer, dims[0]-self.buffer, dims[1]+self.buffer]\n",
    "        gt_expanded = gt_rh.as_rgb(dims=expanded_dims, colorspace=self.colorspace)\n",
    "        aligned = apply_alignment(gt_expanded.transpose(1, 2, 0), row.to_dict())[self.buffer:-self.buffer, self.buffer:-self.buffer]\n",
    "        gt_non_aligned = gt_expanded.transpose(1, 2, 0)[self.buffer:-self.buffer, self.buffer:-self.buffer]\n",
    "        # Convert to tensors\n",
    "        output = {\n",
    "            \"bayer\": torch.tensor(bayer_data).to(float).clip(0,1), \n",
    "            \"gt_non_aligned\": torch.tensor(gt_non_aligned).to(float).permute(2, 0, 1).clip(0,1), \n",
    "            \"aligned\": torch.tensor(aligned).to(float).permute(2, 0, 1).clip(0,1), \n",
    "            # \"sparse\": torch.tensor(sparse).to(float).clip(0,1),\n",
    "            \"noisy\": torch.tensor(noisy).to(float).clip(0,1), \n",
    "            \"rggb\": torch.tensor(rggb).to(float).clip(0,1),\n",
    "            \"conditioning\": torch.tensor([row.iso/self.coordinate_iso]).to(float), \n",
    "            # \"noise_est\": noise_est,\n",
    "            # \"rggb_gt\": rggb_gt,\n",
    "        }\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04525aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.load_config import load_config\n",
    "\n",
    "run_config = load_config()\n",
    "dataset_path = Path(run_config['cropped_raw_subdir'])\n",
    "align_csv = dataset_path / run_config['secondary_align_csv']\n",
    "\n",
    "\n",
    "device=run_config['device']\n",
    "\n",
    "batch_size = run_config['batch_size']\n",
    "lr = run_config['lr_base'] * batch_size\n",
    "clipping =  run_config['clipping']\n",
    "\n",
    "num_epochs = run_config['num_epochs_pretraining']\n",
    "val_split = run_config['val_split']\n",
    "crop_size = run_config['crop_size']\n",
    "experiment = run_config['mlflow_experiment']\n",
    "mlflow_path = run_config['mlflow_path']\n",
    "colorspace = run_config['colorspace']\n",
    "\n",
    "rggb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SmallRawDatasetNumpy(dataset_path, align_csv, colorspace, crop_size=crop_size, validation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b506c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dataset[0]\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ee6bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(output['noisy'].permute(1, 2, 0)**(1/2.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow((output['noisy']-output['aligned']).permute(1, 2, 0)+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow((output['noisy']-output['gt_non_aligned']).permute(1, 2, 0)+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203687d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['gt_non_aligned'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f684a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819fa74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OnSight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
