{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from PIL import Image\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from colour_demosaicing import (\n",
    "    ROOT_RESOURCES_EXAMPLES,\n",
    "    demosaicing_CFA_Bayer_bilinear,\n",
    "    demosaicing_CFA_Bayer_Malvar2004,\n",
    "    demosaicing_CFA_Bayer_Menon2007,\n",
    "    mosaicing_CFA_Bayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6231f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RawHandler.RawHandler import RawHandler\n",
    "from RawHandler.utils import linear_to_srgb\n",
    "from src.training.load_config import load_config\n",
    "\n",
    "def apply_gamma(x, gamma=2.2):\n",
    "    return x ** (1 / gamma)\n",
    "\n",
    "def reverse_gamma(x, gamma=2.2):\n",
    "    return x ** gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e21592",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = load_config()\n",
    "raw_path = Path(run_config['base_data_dir'])\n",
    "outpath = Path(run_config['cropped_raw_subdir'])\n",
    "alignment_csv =  outpath / run_config['align_csv']\n",
    "colorspace = run_config['colorspace']\n",
    "crop_size = run_config['cropped_raw_size']\n",
    "file_list = os.listdir(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783efea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_images_by_scene(file_list, min_iso=100):\n",
    "    \"\"\"\n",
    "    Given a list of RAW image file paths:\n",
    "      1. Extract ISO from filenames\n",
    "      2. Remove files with ISO < min_iso\n",
    "      3. Group by scene name\n",
    "      4. Pair each image with the lowest-ISO version of the scene\n",
    "\n",
    "    Args:\n",
    "        file_list (list of str): Paths to RAW files\n",
    "        min_iso (int): Minimum ISO to keep (default=100)\n",
    "\n",
    "    Returns:\n",
    "        dict: {scene_name: [(img_path, gt_path), ...]}\n",
    "    \"\"\"\n",
    "    iso_pattern = re.compile(r\"_ISO(\\d+)_\")\n",
    "    scene_pairs = {}\n",
    "\n",
    "    # Step 1: Extract iso and scene\n",
    "    images = []\n",
    "    for path in file_list:\n",
    "        filename = os.path.basename(path)\n",
    "        match = iso_pattern.search(filename)\n",
    "        if not match:\n",
    "            continue  # skip if no ISO\n",
    "        iso = int(match.group(1))\n",
    "        if iso < min_iso:\n",
    "            continue  # filter out low ISOs\n",
    "\n",
    "        # Extract scene name:\n",
    "        if \"_GT_\" in filename:\n",
    "            scene = filename.split(\"_GT_\")[0]\n",
    "        else:\n",
    "            # Scene = part before \"_ISO\"\n",
    "            scene = filename.split(\"_ISO\")[0]\n",
    "        if 'X-Trans' in filename:\n",
    "            continue\n",
    "\n",
    "        images.append((scene, iso, path))\n",
    "\n",
    "    # Step 2: Group by scene\n",
    "    grouped = defaultdict(list)\n",
    "    for scene, iso, path in images:\n",
    "        grouped[scene].append((iso, path))\n",
    "\n",
    "    # Step 3: For each scene, pick lowest ISO as GT\n",
    "    for scene, iso_paths in grouped.items():\n",
    "        iso_paths.sort(key=lambda x: x[0])  # sort by ISO ascending\n",
    "        gt_iso, gt_path = iso_paths[0]      # lowest ISO â‰¥ min_iso\n",
    "        pairs = [(path, gt_path) for iso, path in iso_paths if path != gt_path]\n",
    "        scene_pairs[scene] = pairs\n",
    "\n",
    "    return scene_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af686c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_file_list = pair_images_by_scene(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ab100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(impath, crop_size=crop_size):\n",
    "        rh = RawHandler(impath)\n",
    "        \n",
    "        width, height = rh.raw.shape\n",
    "\n",
    "        # Check if the image is large enough to be cropped.\n",
    "        if width < crop_size or height < crop_size:\n",
    "            im = rh.apply_colorspace_transform(colorspace=colorspace)\n",
    "        else:\n",
    "            # Calculate the coordinates for the center crop.\n",
    "            left = (width - crop_size) // 2\n",
    "            top = (height - crop_size) // 2\n",
    "\n",
    "            # Ensure the top-left corner is on an even pixel coordinate for Bayer alignment.\n",
    "            if left % 2 != 0:\n",
    "                left -= 1\n",
    "            if top % 2 != 0:\n",
    "                top -= 1\n",
    "            \n",
    "            # Calculate the bottom-right corner based on the adjusted top-left corner.\n",
    "            # Since crop_size is even, right and bottom will also be even.\n",
    "            right = left + crop_size\n",
    "            bottom = top + crop_size\n",
    "        return rh.raw[left:right, top:bottom], rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b63be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pidng.core import RAW2DNG, DNGTags, Tag\n",
    "from pidng.defs import *\n",
    "\n",
    "def get_ratios(string, rh):\n",
    "    return [x.as_integer_ratio() for x in rh.full_metadata[string].values]\n",
    "\n",
    "\n",
    "def rational_wb(rh, denominator=1000):\n",
    "    wb = np.array(rh.core_metadata.camera_white_balance)\n",
    "    numerator_matrix = np.round(wb * denominator).astype(int)\n",
    "    return [[num, denominator] for num in numerator_matrix]\n",
    "def convert_ccm_to_rational(matrix_3x3, denominator=10000):\n",
    "\n",
    "    numerator_matrix = np.round(matrix_3x3 * denominator).astype(int)\n",
    "    numerators_flat = numerator_matrix.flatten()\n",
    "    ccm_rational = [[num, denominator] for num in numerators_flat]\n",
    "    \n",
    "    return ccm_rational\n",
    "\n",
    "\n",
    "def get_as_shot_neutral(rh, denominator=10000):\n",
    "\n",
    "    cam_mul = rh.core_metadata.camera_white_balance\n",
    "    \n",
    "    if cam_mul[0] == 0 or cam_mul[2] == 0:\n",
    "        return [[denominator, denominator], [denominator, denominator], [denominator, denominator]]\n",
    "\n",
    "    r_neutral = cam_mul[1] / cam_mul[0]\n",
    "    g_neutral = 1.0 \n",
    "    b_neutral = cam_mul[1] / cam_mul[2]\n",
    "\n",
    "    return [\n",
    "        [int(r_neutral * denominator), denominator],\n",
    "        [int(g_neutral * denominator), denominator],\n",
    "        [int(b_neutral * denominator), denominator],\n",
    "    ]\n",
    "\n",
    "\n",
    "def to_dng(uint_img, rh, filepath):\n",
    "    width = uint_img.shape[1]\n",
    "    height = uint_img.shape[0]\n",
    "    bpp = 16\n",
    "\n",
    "    exposures = get_ratios('EXIF ExposureTime', rh)\n",
    "    fnumber = get_ratios('EXIF FNumber', rh)\n",
    "    ExposureBiasValue = get_ratios('EXIF ExposureBiasValue', rh) \n",
    "    FocalLength = get_ratios('EXIF FocalLength', rh) \n",
    "    ccm1 = convert_ccm_to_rational(rh.core_metadata.rgb_xyz_matrix[:3, :])\n",
    "    t = DNGTags()\n",
    "    t.set(Tag.ImageWidth, width)\n",
    "    t.set(Tag.ImageLength, height)\n",
    "    t.set(Tag.TileWidth, width)\n",
    "    t.set(Tag.TileLength, height)\n",
    "    t.set(Tag.BitsPerSample, bpp)\n",
    "\n",
    "    t.set(Tag.SamplesPerPixel, 1) \n",
    "    t.set(Tag.PlanarConfiguration, 1) \n",
    "\n",
    "    t.set(Tag.TileWidth, width)\n",
    "    t.set(Tag.TileLength, height)\n",
    "    t.set(Tag.Orientation, rh.full_metadata['Image Orientation'].values[0])\n",
    "    t.set(Tag.PhotometricInterpretation, PhotometricInterpretation.Color_Filter_Array)\n",
    "    t.set(Tag.CFARepeatPatternDim, [2,2])\n",
    "    t.set(Tag.CFAPattern, CFAPattern.RGGB)\n",
    "    bl = rh.core_metadata.black_level_per_channel\n",
    "    t.set(Tag.BlackLevelRepeatDim, [2,2])\n",
    "    t.set(Tag.BlackLevel, bl)\n",
    "    t.set(Tag.WhiteLevel, rh.core_metadata.white_level)\n",
    "\n",
    "    t.set(Tag.BitsPerSample, bpp)\n",
    "\n",
    "    t.set(Tag.ColorMatrix1, ccm1)\n",
    "    t.set(Tag.CalibrationIlluminant1, CalibrationIlluminant.D65)\n",
    "    wb = get_as_shot_neutral(rh)\n",
    "    t.set(Tag.AsShotNeutral, wb)\n",
    "    t.set(Tag.BaselineExposure, [[0,100]])\n",
    "    t.set(Tag.Make, rh.full_metadata['Image Make'].values)\n",
    "    t.set(Tag.Model, rh.full_metadata['Image Model'].values)\n",
    "\n",
    "\n",
    "\n",
    "    t.set(Tag.FocalLength, FocalLength)\n",
    "    t.set(Tag.EXIFPhotoLensModel, rh.full_metadata['EXIF LensModel'].values)\n",
    "    t.set(Tag.ExposureBiasValue, ExposureBiasValue)\n",
    "    t.set(Tag.ExposureTime, exposures)\n",
    "    t.set(Tag.FNumber, fnumber)\n",
    "    t.set(Tag.PhotographicSensitivity, rh.full_metadata['EXIF ISOSpeedRatings'].values)\n",
    "    t.set(Tag.DNGVersion, DNGVersion.V1_4)\n",
    "    t.set(Tag.DNGBackwardVersion, DNGVersion.V1_2)\n",
    "    t.set(Tag.PreviewColorSpace, PreviewColorSpace.Adobe_RGB)\n",
    "\n",
    "    r = RAW2DNG()\n",
    "\n",
    "    r.options(t, path=\"\", compress=False)\n",
    "\n",
    "    r.convert(uint_img, filename=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07151d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tqdm(pair_file_list.keys()):\n",
    "    image_pairs = pair_file_list[key]\n",
    "    for noisy, gt in image_pairs:\n",
    "        try:\n",
    "            bayer, rh = get_file(f'{raw_path}/{noisy}')\n",
    "            noisy_path = outpath / (noisy)\n",
    "            to_dng(bayer, rh, str(noisy_path))\n",
    "\n",
    "            gt_path = outpath / (gt)\n",
    "            if not os.path.exists(gt_path):\n",
    "                bayer, rh = get_file(f'{raw_path}/{gt}')\n",
    "                to_dng(bayer, rh, str(gt_path))\n",
    "        except:\n",
    "            print(f\"Skipping {raw_path}/{noisy}, {raw_path}/{gt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af6496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcdae9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(impath, crop_size=crop_size):\n",
    "        rh = RawHandler(impath)\n",
    "        \n",
    "        width, height = rh.raw.shape\n",
    "\n",
    "        # Check if the image is large enough to be cropped.\n",
    "        if width < crop_size or height < crop_size:\n",
    "            im = rh.apply_colorspace_transform(colorspace=colorspace)\n",
    "        else:\n",
    "            # Calculate the coordinates for the center crop.\n",
    "            left = (width - crop_size) // 2\n",
    "            top = (height - crop_size) // 2\n",
    "\n",
    "            # Ensure the top-left corner is on an even pixel coordinate for Bayer alignment.\n",
    "            if left % 2 != 0:\n",
    "                left -= 1\n",
    "            if top % 2 != 0:\n",
    "                top -= 1\n",
    "            \n",
    "            # Calculate the bottom-right corner based on the adjusted top-left corner.\n",
    "            # Since crop_size is even, right and bottom will also be even.\n",
    "            right = left + crop_size\n",
    "            bottom = top + crop_size\n",
    "\n",
    "            im = rh.apply_colorspace_transform(dims=(left, right, top, bottom), colorspace=colorspace)\n",
    "            im = im.astype(np.float16)\n",
    "        # im_scaled = im * 65535.0\n",
    "        # im_clipped = np.clip(im_scaled, 0.0, 65535.0)\n",
    "\n",
    "        # im_uint16 = im_clipped.astype(np.uint16)\n",
    "        return im, rh.raw[left:right, top:bottom], rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010774f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tqdm(pair_file_list.keys()):\n",
    "    image_pairs = pair_file_list[key]\n",
    "    for noisy, gt in image_pairs:\n",
    "        try:\n",
    "            noisy_bayer = get_file(f'{raw_path}/{noisy}')\n",
    "            noisy_path = outpath / (noisy + \".f16.raw\")\n",
    "            noisy_bayer.tofile(noisy_path)\n",
    "\n",
    "            gt_path = outpath / (gt + \".f16.raw\")\n",
    "            if not os.path.exists(gt_path):\n",
    "                gt_bayer = get_file(f'{raw_path}/{gt}')\n",
    "                gt_bayer.tofile(gt_path)\n",
    "        except:\n",
    "            print(f\"Skipping {raw_path}/{noisy}, {raw_path}/{gt}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(Tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pidng.core import RAW2DNG, DNGTags, Tag\n",
    "from pidng.defs import *\n",
    "\n",
    "def get_ratios(string, rh):\n",
    "    return [x.as_integer_ratio() for x in rh.full_metadata[string].values]\n",
    "\n",
    "\n",
    "def rational_wb(rh, denominator=1000):\n",
    "    wb = np.array(rh.core_metadata.camera_white_balance)\n",
    "    numerator_matrix = np.round(wb * denominator).astype(int)\n",
    "    return [[num, denominator] for num in numerator_matrix]\n",
    "def convert_ccm_to_rational(matrix_3x3, denominator=10000):\n",
    "\n",
    "    numerator_matrix = np.round(matrix_3x3 * denominator).astype(int)\n",
    "    numerators_flat = numerator_matrix.flatten()\n",
    "    ccm_rational = [[num, denominator] for num in numerators_flat]\n",
    "    \n",
    "    return ccm_rational\n",
    "\n",
    "\n",
    "def get_as_shot_neutral(rh, denominator=10000):\n",
    "\n",
    "    # Get multipliers [R, G1, B, G2]\n",
    "    cam_mul = rh.core_metadata.camera_white_balance\n",
    "    \n",
    "    # Check for zero multipliers to avoid division by zero\n",
    "    if cam_mul[0] == 0 or cam_mul[2] == 0:\n",
    "        # Fallback to [1, 1, 1] if multipliers are bad\n",
    "        return [[denominator, denominator], [denominator, denominator], [denominator, denominator]]\n",
    "\n",
    "    # Calculate inverse multipliers normalized to G (cam_mul[1])\n",
    "    # DNG spec AsShotNeutral = [1/R_scale, 1/G_scale, 1/B_scale]\n",
    "    # where G_scale = 1.0. This means:\n",
    "    # R_scale = R_mult / G_mult\n",
    "    # B_scale = B_mult / G_mult\n",
    "    # So 1/R_scale = G_mult / R_mult\n",
    "    \n",
    "    r_neutral = cam_mul[1] / cam_mul[0]\n",
    "    g_neutral = 1.0  # G is always 1.0\n",
    "    b_neutral = cam_mul[1] / cam_mul[2]\n",
    "\n",
    "    return [\n",
    "        [int(r_neutral * denominator), denominator],\n",
    "        [int(g_neutral * denominator), denominator],\n",
    "        [int(b_neutral * denominator), denominator],\n",
    "    ]\n",
    "\n",
    "\n",
    "def to_dng(uint_img, rh, filepath):\n",
    "    uint_img = np.ascontiguousarray(uint_img)\n",
    "    width = uint_img.shape[1]\n",
    "    height = uint_img.shape[0]\n",
    "    bpp = 16\n",
    "\n",
    "    exposures = get_ratios('EXIF ExposureTime', rh)\n",
    "    fnumber = get_ratios('EXIF FNumber', rh)\n",
    "    ExposureBiasValue = get_ratios('EXIF ExposureBiasValue', rh) \n",
    "    FocalLength = get_ratios('EXIF FocalLength', rh) \n",
    "    ccm1 = convert_ccm_to_rational(rh.core_metadata.rgb_xyz_matrix[:3, :])\n",
    "    t = DNGTags()\n",
    "    t.set(Tag.ImageWidth, width)\n",
    "    t.set(Tag.ImageLength, height)\n",
    "    t.set(Tag.TileWidth, width)\n",
    "    t.set(Tag.TileLength, height)\n",
    "    t.set(Tag.BitsPerSample, bpp)\n",
    "\n",
    "    t.set(Tag.SamplesPerPixel, 1) \n",
    "    t.set(Tag.PlanarConfiguration, 1) \n",
    "\n",
    "    t.set(Tag.TileWidth, width)\n",
    "    t.set(Tag.TileLength, height)\n",
    "    t.set(Tag.Orientation, rh.full_metadata['Image Orientation'].values[0])\n",
    "    t.set(Tag.PhotometricInterpretation, PhotometricInterpretation.Color_Filter_Array)\n",
    "    t.set(Tag.CFARepeatPatternDim, [2,2])\n",
    "    t.set(Tag.CFAPattern, CFAPattern.RGGB)\n",
    "    bl = rh.core_metadata.black_level_per_channel\n",
    "    t.set(Tag.BlackLevelRepeatDim, [2,2])\n",
    "    t.set(Tag.BlackLevel, bl)\n",
    "    t.set(Tag.WhiteLevel, rh.core_metadata.white_level)\n",
    "\n",
    "    t.set(Tag.BitsPerSample, bpp)\n",
    "\n",
    "    t.set(Tag.ColorMatrix1, ccm1)\n",
    "    t.set(Tag.CalibrationIlluminant1, CalibrationIlluminant.D65)\n",
    "    wb = get_as_shot_neutral(rh)\n",
    "    print(wb)\n",
    "    t.set(Tag.AsShotNeutral, wb)\n",
    "    t.set(Tag.BaselineExposure, [[0,100]])\n",
    "    t.set(Tag.Make, rh.full_metadata['Image Make'].values)\n",
    "    t.set(Tag.Model, rh.full_metadata['Image Model'].values)\n",
    "\n",
    "\n",
    "\n",
    "    t.set(Tag.FocalLength, FocalLength)\n",
    "    t.set(Tag.EXIFPhotoLensModel, rh.full_metadata['EXIF LensModel'].values)\n",
    "    t.set(Tag.ExposureBiasValue, ExposureBiasValue)\n",
    "    t.set(Tag.ExposureTime, exposures)\n",
    "    t.set(Tag.FNumber, fnumber)\n",
    "    t.set(Tag.PhotographicSensitivity, rh.full_metadata['EXIF ISOSpeedRatings'].values)\n",
    "    t.set(Tag.DNGVersion, DNGVersion.V1_4)\n",
    "    t.set(Tag.DNGBackwardVersion, DNGVersion.V1_2)\n",
    "    t.set(Tag.PreviewColorSpace, PreviewColorSpace.Adobe_RGB)\n",
    "\n",
    "    r = RAW2DNG()\n",
    "\n",
    "    r.options(t, path=\"\", compress=False)\n",
    "\n",
    "    r.convert(uint_img, filename=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d424c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tag.BlackLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cf0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "im, raw, rh = get_file(f'{raw_path}/{noisy}')\n",
    "width, height = rh.raw.shape\n",
    "\n",
    "# Check if the image is large enough to be cropped.\n",
    "if width < crop_size or height < crop_size:\n",
    "    im = rh.apply_colorspace_transform( colorspace=colorspace)\n",
    "else:\n",
    "    # Calculate the coordinates for the center crop.\n",
    "    left = (width - crop_size) // 2\n",
    "    top = (height - crop_size) // 2\n",
    "\n",
    "    # Ensure the top-left corner is on an even pixel coordinate for Bayer alignment.\n",
    "    if left % 2 != 0:\n",
    "        left -= 1\n",
    "    if top % 2 != 0:\n",
    "        top -= 1\n",
    "    \n",
    "    # Calculate the bottom-right corner based on the adjusted top-left corner.\n",
    "    # Since crop_size is even, right and bottom will also be even.\n",
    "    right = left + crop_size\n",
    "    bottom = top + crop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9010156",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.raw.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28809a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = rh.as_rgb(dims=(left, right, top, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.core_metadata.raw_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im.transpose(1, 2, 0)**(1/2.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.raw[left:right, top:bottom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhdng.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.core_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dng(raw, rh, \"test_camera_WB_D65_compress\")\n",
    "rhdng = RawHandler(\"test_camera_WB_D65_compress.dng\")\n",
    "rhdng.core_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhdng.raw.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.raw[left:right, top:bottom].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fe790",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.80898881*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7943162",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.80864525*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a368fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = rhdng.as_rgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c73bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im2.transpose(1, 2, 0)**(1/2.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f25ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.load_config import load_config\n",
    "from src.training.SmallRawDatasetNumpy import SmallRawDatasetNumpy\n",
    "from src.training.censored_fit import censored_linear_fit_twosided\n",
    "\n",
    "run_config = load_config()\n",
    "dataset_path = Path(run_config['cropped_raw_subdir'])\n",
    "align_csv = dataset_path / run_config['secondary_align_csv']\n",
    "crop_size = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SmallRawDatasetNumpy(dataset_path, align_csv, crop_size=crop_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e363d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f39a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output['aligned'].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad377b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhdng = RawHandler(\"test_camera_WB_D65_compress.dng\")\n",
    "rh = RawHandler('/Volumes/EasyStore/RAWNIND/Bayer_MuseeL-sol-A7C-brighter_ISO100_sha1=18eaa9931d9a0f6f0511552ef6bf2fd040d82878.arw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = rh.raw.shape\n",
    "\n",
    "# Check if the image is large enough to be cropped.\n",
    "if width < crop_size or height < crop_size:\n",
    "    im = rh.apply_colorspace_transform( colorspace=colorspace)\n",
    "else:\n",
    "    # Calculate the coordinates for the center crop.\n",
    "    left = (width - crop_size) // 2\n",
    "    top = (height - crop_size) // 2\n",
    "\n",
    "    # Ensure the top-left corner is on an even pixel coordinate for Bayer alignment.\n",
    "    if left % 2 != 0:\n",
    "        left -= 1\n",
    "    if top % 2 != 0:\n",
    "        top -= 1\n",
    "    \n",
    "    # Calculate the bottom-right corner based on the adjusted top-left corner.\n",
    "    # Since crop_size is even, right and bottom will also be even.\n",
    "    right = left + crop_size\n",
    "    bottom = top + crop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ded325",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.raw[left:right, top:bottom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhdng.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fa141",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdng = rhdng.as_rgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45796c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = rh.as_rgb(dims=(left, right, top, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdng-im).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe26aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45323089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OnSight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
