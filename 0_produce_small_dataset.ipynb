{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from PIL import Image\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from colour_demosaicing import (\n",
    "    ROOT_RESOURCES_EXAMPLES,\n",
    "    demosaicing_CFA_Bayer_bilinear,\n",
    "    demosaicing_CFA_Bayer_Malvar2004,\n",
    "    demosaicing_CFA_Bayer_Menon2007,\n",
    "    mosaicing_CFA_Bayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6231f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RawHandler.RawHandler import RawHandler\n",
    "from RawHandler.utils import linear_to_srgb\n",
    "from src.training.load_config import load_config\n",
    "\n",
    "def apply_gamma(x, gamma=2.2):\n",
    "    return x ** (1 / gamma)\n",
    "\n",
    "def reverse_gamma(x, gamma=2.2):\n",
    "    return x ** gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e21592",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = load_config()\n",
    "raw_path = Path(run_config['base_data_dir'])\n",
    "outpath = Path(run_config['jpeg_output_subdir'])\n",
    "alignment_csv =  outpath / run_config['align_csv']\n",
    "outpath_cropped =  run_config['cropped_jpeg_subdir']\n",
    "colorspace = run_config['colorspace']\n",
    "\n",
    "file_list = os.listdir(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783efea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_images_by_scene(file_list, min_iso=100):\n",
    "    \"\"\"\n",
    "    Given a list of RAW image file paths:\n",
    "      1. Extract ISO from filenames\n",
    "      2. Remove files with ISO < min_iso\n",
    "      3. Group by scene name\n",
    "      4. Pair each image with the lowest-ISO version of the scene\n",
    "\n",
    "    Args:\n",
    "        file_list (list of str): Paths to RAW files\n",
    "        min_iso (int): Minimum ISO to keep (default=100)\n",
    "\n",
    "    Returns:\n",
    "        dict: {scene_name: [(img_path, gt_path), ...]}\n",
    "    \"\"\"\n",
    "    iso_pattern = re.compile(r\"_ISO(\\d+)_\")\n",
    "    scene_pairs = {}\n",
    "\n",
    "    # Step 1: Extract iso and scene\n",
    "    images = []\n",
    "    for path in file_list:\n",
    "        filename = os.path.basename(path)\n",
    "        match = iso_pattern.search(filename)\n",
    "        if not match:\n",
    "            continue  # skip if no ISO\n",
    "        iso = int(match.group(1))\n",
    "        if iso < min_iso:\n",
    "            continue  # filter out low ISOs\n",
    "\n",
    "        # Extract scene name:\n",
    "        if \"_GT_\" in filename:\n",
    "            scene = filename.split(\"_GT_\")[0]\n",
    "        else:\n",
    "            # Scene = part before \"_ISO\"\n",
    "            scene = filename.split(\"_ISO\")[0]\n",
    "        if 'X-Trans' in filename:\n",
    "            continue\n",
    "\n",
    "        images.append((scene, iso, path))\n",
    "\n",
    "    # Step 2: Group by scene\n",
    "    grouped = defaultdict(list)\n",
    "    for scene, iso, path in images:\n",
    "        grouped[scene].append((iso, path))\n",
    "\n",
    "    # Step 3: For each scene, pick lowest ISO as GT\n",
    "    for scene, iso_paths in grouped.items():\n",
    "        iso_paths.sort(key=lambda x: x[0])  # sort by ISO ascending\n",
    "        gt_iso, gt_path = iso_paths[0]      # lowest ISO â‰¥ min_iso\n",
    "        pairs = [(path, gt_path) for iso, path in iso_paths if path != gt_path]\n",
    "        scene_pairs[scene] = pairs\n",
    "\n",
    "    return scene_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f13812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_warp_matrix(img1_gray, img2_gray, num_features=2000):\n",
    "    \"\"\"\n",
    "    Finds an initial warp matrix using ORB feature matching.\n",
    "\n",
    "    Args:\n",
    "        img1_gray (np.array): The first grayscale image (template).\n",
    "        img2_gray (np.array): The second grayscale image (to be warped).\n",
    "        num_features (int): The number of features for ORB to detect.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The 2x3 Euclidean warp matrix, or the identity matrix if it fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize ORB detector\n",
    "        orb = cv2.ORB_create(nfeatures=num_features)\n",
    "\n",
    "        # Find the keypoints and descriptors with ORB\n",
    "        keypoints1, descriptors1 = orb.detectAndCompute(img1_gray, None)\n",
    "        keypoints2, descriptors2 = orb.detectAndCompute(img2_gray, None)\n",
    "        \n",
    "        # Descriptors can be None if no keypoints are found\n",
    "        if descriptors1 is None or descriptors2 is None:\n",
    "            return np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "        # Create BFMatcher object\n",
    "        # NORM_HAMMING is used for binary descriptors like ORB\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "        # Match descriptors\n",
    "        matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "        # Sort them in the order of their distance (best matches first)\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "        # Keep only the top matches (e.g., top 50 or 15% of matches)\n",
    "        num_good_matches = min(len(matches), 50)\n",
    "        if num_good_matches < 10: # Need at least ~6-10 points for a robust estimate\n",
    "            return np.eye(2, 3, dtype=np.float32)\n",
    "            \n",
    "        matches = matches[:num_good_matches]\n",
    "\n",
    "        # Extract location of good matches\n",
    "        points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "        for i, match in enumerate(matches):\n",
    "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "        # Find the rigid transformation (Euclidean) using RANSAC\n",
    "        # cv2.estimateAffinePartial2D is perfect for finding a Euclidean transform\n",
    "        warp_matrix, _ = cv2.estimateAffinePartial2D(points2, points1, method=cv2.RANSAC)\n",
    "        \n",
    "        # If estimation fails, it returns None\n",
    "        if warp_matrix is None:\n",
    "            return np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "        return warp_matrix.astype(np.float32)\n",
    "\n",
    "    except cv2.error as e:\n",
    "        print(f\"OpenCV error during feature matching: {e}\")\n",
    "        return np.eye(2, 3, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9504cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_warp_dataframe(warp_matrix):\n",
    "    \"\"\"\n",
    "    Save warp matrix + metadata into a CSV with pandas.\n",
    "    warp_matrix: 2x3 or 3x3 numpy array\n",
    "    metadata: dict of other info\n",
    "    \"\"\"\n",
    "    flat = warp_matrix.flatten()\n",
    "    cols = [f\"m{i}{j}\" for i in range(warp_matrix.shape[0]) for j in range(warp_matrix.shape[1])]\n",
    "    row = dict(zip(cols, flat))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_align_hybrid(noisy_fname, gt_fname, path, downsample_factor=4):\n",
    "    \"\"\"\n",
    "    Hybrid function to align images using feature-based pre-alignment (coarse)\n",
    "    and ECC (fine).\n",
    "    \"\"\"\n",
    "    # 1. Load raw files\n",
    "    noisy_handler = RawHandler(f'{path}/{noisy_fname}', colorspace=colorspace)\n",
    "    gt_handler = RawHandler(f'{path}/{gt_fname}', colorspace=colorspace)\n",
    "\n",
    "    noisy_bayer = noisy_handler.apply_colorspace_transform(colorspace='lin_rec2020', clip=True).astype(np.float32)\n",
    "    gt_bayer = gt_handler.apply_colorspace_transform(colorspace='lin_rec2020', clip=True).astype(np.float32)\n",
    "    noisy_bayer = apply_gamma(noisy_bayer)\n",
    "    gt_bayer = apply_gamma(gt_bayer)\n",
    "    \n",
    "    noisy_image = demosaicing_CFA_Bayer_Malvar2004(noisy_bayer)\n",
    "    gt_image = demosaicing_CFA_Bayer_Malvar2004(gt_bayer)\n",
    "    noisy_image = np.clip(noisy_image, 0, 1)\n",
    "    gt_image = np.clip(gt_image, 0, 1)\n",
    "\n",
    "\n",
    "    # Note: OpenCV expects BGR order, RawHandler might give RGB. Ensure consistency.\n",
    "    # Assuming BGR for cvtColor. If RGB, use cv2.COLOR_RGB2GRAY.\n",
    "    gt_image_uint8 = (gt_image * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    noisy_image_uint8 = (noisy_image * 255.0).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "    # 3. Convert to grayscale using the faster uint8 versions\n",
    "    noisy_gray = cv2.cvtColor(noisy_image_uint8, cv2.COLOR_BGR2GRAY)\n",
    "    gt_gray = cv2.cvtColor(gt_image_uint8, cv2.COLOR_BGR2GRAY)\n",
    "    h, w = noisy_gray.shape\n",
    "\n",
    "    # 4. --- NEW: Get initial warp matrix from feature matching ---\n",
    "    # We run this on the full-res grayscale images for better keypoint detection\n",
    "    warp_matrix = get_initial_warp_matrix(gt_gray, noisy_gray)\n",
    "\n",
    "    # 5. Downsample for ECC refinement\n",
    "    if downsample_factor > 1:\n",
    "        # We need to scale the initial guess to the downsampled size\n",
    "        warp_matrix_scaled = warp_matrix.copy()\n",
    "        warp_matrix_scaled[0, 2] /= downsample_factor\n",
    "        warp_matrix_scaled[1, 2] /= downsample_factor\n",
    "\n",
    "        noisy_gray_small = cv2.resize(noisy_gray, (w // downsample_factor, h // downsample_factor), interpolation=cv2.INTER_AREA)\n",
    "        gt_gray_small = cv2.resize(gt_gray, (w // downsample_factor, h // downsample_factor), interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        noisy_gray_small = noisy_gray\n",
    "        gt_gray_small = gt_gray\n",
    "        warp_matrix_scaled = warp_matrix\n",
    "\n",
    "    # 6. ECC alignment (refinement) using the improved initial guess\n",
    "    warp_mode = cv2.MOTION_EUCLIDEAN\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 200, 1e-5)\n",
    "    # We provide `warp_matrix_scaled` as the initial guess!\n",
    "    try:\n",
    "\n",
    "        (cc, warp_matrix_final_scaled) = cv2.findTransformECC(gt_gray_small, noisy_gray_small, warp_matrix_scaled, warp_mode, criteria)\n",
    "    except cv2.error:\n",
    "        # If ECC fails, use the initial matrix from feature matching\n",
    "        cc = -1.0 # Indicate failure or that we used the fallback\n",
    "        warp_matrix_final_scaled = warp_matrix_scaled\n",
    "    \n",
    "    # 7. Scale the final matrix translation back to full resolution\n",
    "    \n",
    "    warp_matrix_final = warp_matrix_final_scaled.copy()\n",
    "    if downsample_factor > 1:\n",
    "        warp_matrix_final[0, 2] *= downsample_factor\n",
    "        warp_matrix_final[1, 2] *= downsample_factor\n",
    "\n",
    "    # 8. Warp the original full-resolution FLOAT image\n",
    "    gt_aligned = cv2.warpAffine(gt_image, warp_matrix_final, (w, h), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "    # 9. Metadata / stats\n",
    "    try:\n",
    "        iso = float(re.findall('ISO([0-9]+)', noisy_fname)[0])\n",
    "    except (IndexError, ValueError):\n",
    "        iso = 0\n",
    "\n",
    "    info_dict = {\n",
    "        \"cc\": cc,\n",
    "        \"noisy_image\": noisy_fname,\n",
    "        \"gt_image\": gt_fname,\n",
    "        \"gt_mean\": gt_image.mean(),\n",
    "        \"noisy_mean\": noisy_image.mean(),\n",
    "        \"noise_level\": (noisy_image-gt_image).std(axis=(0,1)),\n",
    "        **save_warp_dataframe(warp_matrix_final),\n",
    "        \"iso\": iso,\n",
    "    }\n",
    "\n",
    "    return info_dict, noisy_image, gt_aligned, noisy_bayer[0], gt_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af686c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_file_list = pair_images_by_scene(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_8bit(x):\n",
    "    return (x * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb696eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop so we can visualize the alignment performance\n",
    "\n",
    "list = []\n",
    "idx = 0\n",
    "for key in pair_file_list.keys():\n",
    "    image_pairs = pair_file_list[key]\n",
    "    print(idx, idx/len(pair_file_list))\n",
    "    idx+=1\n",
    "    jdx = 0\n",
    "    for (noise, gt) in image_pairs:\n",
    "        output, noisy_image, gt_aligned, noisy_bayer, gt_image = get_align_hybrid(noise, gt, path, downsample_factor=1)\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11269156",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(2, 3, figsize=(30, 20))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(noisy_image[1000:1100, 3000:3100])\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(noisy_bayer[1000:1100, 3000:3100])\n",
    "\n",
    "plt.subplot(2,3, 3)\n",
    "plt.imshow(gt_image[1000:1100, 3000:3100])\n",
    "\n",
    "\n",
    "plt.subplot(2,3, 4)\n",
    "plt.imshow(noisy_image[1000:1100, 3000:3100]-gt_image[1000:1100, 3000:3100]+0.5)\n",
    "\n",
    "\n",
    "plt.subplot(2,3, 5)\n",
    "plt.imshow(noisy_image[1000:1100, 3000:3100]-gt_aligned[1000:1100, 3000:3100]+0.5)\n",
    "\n",
    "plt.subplot(2,3, 6)\n",
    "# plt.imshow(noisy_bayer[1000:1100, 3000:3100]-noisy_image[1000:1100, 3000:3100]+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e1066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align and save the jpegs\n",
    "list = []\n",
    "idx = 0\n",
    "for key in pair_file_list.keys():\n",
    "    image_pairs = pair_file_list[key]\n",
    "    print(idx, idx/len(pair_file_list))\n",
    "    idx+=1\n",
    "    jdx = 0\n",
    "    for (noise, gt) in image_pairs:\n",
    "        try:\n",
    "            output, noisy_image, gt_aligned, noisy_bayer, gt_image = get_align_hybrid(noise, gt, path, downsample_factor=1)\n",
    "            list.append(output)\n",
    "            noisy_image\n",
    "            imageio.imwrite(f\"{outpath}/{noise}.jpg\", as_8bit(noisy_image), quality=100)\n",
    "            imageio.imwrite(f\"{outpath}/{noise}_bayer.jpg\", as_8bit(noisy_bayer), quality=100)\n",
    "            if jdx==0:\n",
    "                imageio.imwrite(f\"{outpath}/{gt}.jpg\", as_8bit(gt_image), quality=100)\n",
    "            jdx+=1\n",
    "        except:\n",
    "            print(f\"skipping {noise}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bab144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list)\n",
    "df.to_csv(alignment_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337da98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "## The following code allows for the existing dataset to be further reduced by cropping into center squares\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7517af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved dataset and visualize alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(alignment_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb194bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[-2]\n",
    "\n",
    "# Get Row Matrix\n",
    "shape=(2,3)\n",
    "cols = [f\"m{i}{j}\" for i in range(shape[0]) for j in range(shape[1])]\n",
    "flat = np.array([row.pop(c) for c in cols], dtype=np.float32)\n",
    "warp_matrix = flat.reshape(shape)\n",
    "warp_matrix\n",
    "\n",
    "\n",
    "noisy_name = row.noisy_image\n",
    "gt_name = row.gt_image\n",
    "\n",
    "with imageio.imopen(f\"{outpath}/{noisy_name}_bayer.jpg\", \"r\") as image_resource:\n",
    "    bayer_data = image_resource.read()\n",
    "\n",
    "with imageio.imopen(f\"{outpath}/{noisy_name}.jpg\", \"r\") as image_resource:\n",
    "    noisy = image_resource.read()\n",
    "\n",
    "\n",
    "with imageio.imopen(f\"{outpath}/{gt_name}.jpg\", \"r\") as image_resource:\n",
    "    gt_image = image_resource.read()\n",
    "\n",
    "noisy = noisy/255\n",
    "gt_image = gt_image/255\n",
    "bayer_data = bayer_data/255\n",
    "h, w, _ = noisy.shape\n",
    "gt = cv2.warpAffine(gt_image, warp_matrix, (w, h), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "warp_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621a322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demosaiced = demosaicing_CFA_Bayer_Malvar2004(bayer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8dbf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(2, 3, figsize=(30, 20))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(noisy[1000:1100, 3000:3100])\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(demosaiced[1000:1100, 3000:3100])\n",
    "\n",
    "plt.subplot(2,3, 3)\n",
    "plt.imshow(gt[1000:1100, 3000:3100])\n",
    "\n",
    "\n",
    "plt.subplot(2,3, 4)\n",
    "plt.imshow(gt[1000:1100, 3000:3100]-demosaiced[1000:1100, 3000:3100]+0.5)\n",
    "\n",
    "\n",
    "plt.subplot(2,3, 5)\n",
    "plt.imshow(noisy[1000:1100, 3000:3100]-demosaiced[1000:1100, 3000:3100]+0.5) \n",
    "\n",
    "plt.subplot(2,3, 6)\n",
    "plt.imshow(noisy[1000:1100, 3000:3100]-gt_image[1000:1100, 3000:3100]+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Crop to center to save even more space\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop_center_square(input_dir, output_dir, crop_size):\n",
    "    \"\"\"\n",
    "    Loops over image files in a directory, crops a center square, and saves them.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): The path to the directory containing the original images.\n",
    "        output_dir (str): The path to the directory where cropped images will be saved.\n",
    "        crop_size (int): The width and height of the square to crop (must be an even number).\n",
    "    \"\"\"\n",
    "    # --- 1. Input Validation ---\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"Error: Input directory not found at '{input_dir}'\")\n",
    "        return\n",
    "\n",
    "    if crop_size % 2 != 0:\n",
    "        print(f\"Error: Crop size must be an even number. You provided {crop_size}.\")\n",
    "        return\n",
    "        \n",
    "    # --- 2. Create Output Directory ---\n",
    "    # Create the output directory if it doesn't already exist.\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Output will be saved to: '{output_dir}'\")\n",
    "\n",
    "    # --- 3. Process Images ---\n",
    "    # Get a list of all files in the input directory.\n",
    "    files = os.listdir(input_dir)\n",
    "\n",
    "    processed_count = 0\n",
    "    for filename in files:\n",
    "        # Construct the full path for the input file.\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        # Process only files, not subdirectories.\n",
    "        if os.path.isfile(input_path):\n",
    "            try:\n",
    "                # Open the image using Pillow.\n",
    "                with Image.open(input_path) as img:\n",
    "                    width, height = img.size\n",
    "\n",
    "                    # Check if the image is large enough to be cropped.\n",
    "                    if width < crop_size or height < crop_size:\n",
    "                        print(f\"Skipping '{filename}': smaller than crop size.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate the coordinates for the center crop.\n",
    "                    left = (width - crop_size) // 2\n",
    "                    top = (height - crop_size) // 2\n",
    "\n",
    "                    # Ensure the top-left corner is on an even pixel coordinate for Bayer alignment.\n",
    "                    if left % 2 != 0:\n",
    "                        left -= 1\n",
    "                    if top % 2 != 0:\n",
    "                        top -= 1\n",
    "                    \n",
    "                    # Calculate the bottom-right corner based on the adjusted top-left corner.\n",
    "                    # Since crop_size is even, right and bottom will also be even.\n",
    "                    right = left + crop_size\n",
    "                    bottom = top + crop_size\n",
    "\n",
    "                    # Perform the crop. The box is a 4-tuple defining the left, upper, right, and lower pixel coordinate.\n",
    "                    img_cropped = np.array(img.crop((left, top, right, bottom)))\n",
    "\n",
    "                    # Construct the full path for the output file.\n",
    "                    output_path = os.path.join(output_dir, filename)\n",
    "                    \n",
    "                    # Save the cropped image.\n",
    "                    # img_cropped.save(output_path)\n",
    "                    imageio.imwrite(output_path,img_cropped, quality=95)\n",
    "                    processed_count += 1\n",
    "\n",
    "            except (IOError, OSError) as e:\n",
    "                # Handle cases where the file is not a valid image.\n",
    "                print(f\"Could not process '{filename}'. It might not be an image file. Error: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred with file '{filename}': {e}\")\n",
    "                \n",
    "    print(f\"\\nProcessing complete. Cropped {processed_count} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_center_square(outpath, outpath_cropped, crop_size=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OnSight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
